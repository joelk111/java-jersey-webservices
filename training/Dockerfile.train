# Dockerfile for LoRA Training
# Run locally with GPU support
#
# Build:
#   docker build -f training/Dockerfile.train -t rules-engine-train .
#
# Run training:
#   docker run --gpus all -v $(pwd)/training:/app/training rules-engine-train

FROM nvidia/cuda:12.1-devel-ubuntu22.04

# Set environment
ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1
ENV CUDA_HOME=/usr/local/cuda

# Install system dependencies
RUN apt-get update && apt-get install -y \
    python3.11 \
    python3.11-dev \
    python3-pip \
    git \
    wget \
    cmake \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

# Set Python 3.11 as default
RUN update-alternatives --install /usr/bin/python python /usr/bin/python3.11 1 \
    && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.11 1

# Upgrade pip
RUN python -m pip install --upgrade pip setuptools wheel

# Install PyTorch with CUDA support
RUN pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# Install training dependencies
RUN pip install \
    transformers>=4.36.0 \
    datasets>=2.14.0 \
    accelerate>=0.25.0 \
    peft>=0.7.0 \
    bitsandbytes>=0.41.0 \
    trl>=0.7.0 \
    scipy \
    sentencepiece \
    protobuf

# Install Unsloth for faster training
RUN pip install "unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git"

# Clone llama.cpp for GGUF conversion
RUN git clone https://github.com/ggerganov/llama.cpp /opt/llama.cpp \
    && cd /opt/llama.cpp \
    && pip install -r requirements.txt \
    && make -j$(nproc)

ENV PATH="/opt/llama.cpp:${PATH}"

# Create working directory
WORKDIR /app

# Copy training scripts
COPY training/ /app/training/
COPY sample_rules.csv /app/
COPY sample_rules_json.csv /app/
COPY rules.py /app/

# Make scripts executable
RUN chmod +x /app/training/*.py

# Default command: generate data and train
CMD ["bash", "-c", "\
    echo '=== Generating training data ===' && \
    python /app/training/generate_training_data.py && \
    echo '=== Starting LoRA training ===' && \
    python /app/training/train_lora.py --backend unsloth --epochs 3 && \
    echo '=== Exporting to Ollama format ===' && \
    python /app/training/export_to_ollama.py \
"]
